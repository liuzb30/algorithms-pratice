## 数据结构之----哈夫曼树

### 概念

#### 1.1 路径长度

`路径`：从一个节点到另一个节点之间的分支构成这两点之间的路径

`路径长度`：路径上的分支条数，树的路径长度是从树的根节点到每个节点的路径长度之和

#### 1.2 带权路径长度

`扩充二叉树`：每个叶节点有对应的权值的二叉树。
`带权路径长度`: 路径长度和该节点的权值的乘积。
`哈夫曼树`：带权路径长度最小的二叉树就是哈夫曼树，节点权值越大，距离根节点就越近

#### 1.3 哈夫曼算法

哈夫曼算法是构造权值集合为 { w1, ... wn } 的哈夫曼树，其算法思路如下

1.根据给定的 n 个权值 { w1, ... wn }， 构造具有 n 棵扩充二叉树的森林 F = { T1, ... Tn}, 对于每棵扩充二叉树 Ti 只有一个带权值的 wi 的根节点，左右子树都为空

2.重复以下步骤，直到 F 中只剩下一棵树为止

- 在 F 中选取两棵根节点的权值最小的扩充二叉树，把这两棵树作为左右子树构造一棵新的二叉树，这个新的二叉树的根节点的权值为其左右两棵子树根节点的权值之和
- 在 F 中删除第一步中选取的两棵二叉树
- 将第一步中构造的新的二叉树加入到 F 中

最后得到的就是哈夫曼树

### 2. 哈夫曼编码

在通信领域，经过哈夫曼编码的的信息小于大量冗余数据，提高传输效率，是重要的数据压缩方法。

## 数据结构之----二叉搜索树

### 1.概念

二叉搜索树具有一下四点性质：

- 所有节点关键码都互不相同
- 左子树上所有节点的关键码都小于根节点的关键码
- 右子树上所有节点的关键码都大于根节点的关键码
- 左右子树也是二叉搜索树

对二叉搜索树进行中序遍历，就可以按照关键码的大小从小到大的顺序将各节点排列起来，因此，二叉搜索树也叫二叉排序树

### 2.实现

#### 2.1 插入

插入时，从根节点开始，被插入元素的关键码如果比根节点关键码小，则进入到左子树中执行插入操作，如果左子树不存在，则被插入元素成为左孩子；反之，进入到右子树中执行插入操作，如果右子树不存在，则被插入元素成为右孩子，如果被插入元素的关键码已经存在，则返回 false。

#### 2.2 搜索

与插入算法非常接近，仍然是从树的根节点开始，如果被搜索元素的关键码比根节点关键码小，则进入到左子树中进行搜索，若左子树不存在，返回 null，如果被搜索元素的关键码比根节点关键码大，则进入到右子树中进行搜索，若右子树不存在，返回 null,如果根节点的关键码和被搜索元素的关键码相同，返回这个根节点。

#### 2.3 删除

删除一个节点时，要考虑到必须将被删除节点的子孙节点连接到树上，同时保证二叉搜索树的性质。

根据被删除节点的左右子孩子，可以总结一下几种情况：

- 被删除节点左右孩子都不存在
- 被删除节点没有右孩子
- 被删除节点没有左孩子
- 被删除节点左右孩子都存在

对于第 1 种情况，最为简单，只需要让其父节点指向它的指针指向 null 即可
对于第 2 种情况，用左孩子替代它的位置
对于第 3 种情况，用右孩子替代他的位置
对于第 4 中情况，稍稍有些复杂，首先，去被删除节点的右子树中找到中序遍历下的第一个节点，假设节点的 data 数据为 x，将被删除节点的 data 替换成 x，而后，在被删除节点的右子树中执行删除 x 的操作

## 数据结构之----平衡二叉树(AVL 树)

AVL 树首先是一棵二叉搜索树，但它具备自平衡的能力，它的左右子树都是 AVL 树，且左右子树的高度差的绝对值不超过 1。

#### 插入时的平衡化旋转

对于一棵 AVL 树，它的任意一个节点的平衡因子都只能取 -1， 0， 1 中的一个，如果节点的平衡因子绝对值大于 1，则 AVL 数失去了平衡性。

有四种平衡旋转方式使其重新平衡:

- 左单旋转
- 右单旋转
- 先左后右双旋转
- 先右后左双旋转

#### 删除时的平衡化处理

AVL 树在删除的时候，其操作方式和二叉搜索树是一样的，不同的地方在于，由于删除了一个节点，它的 parent 的平衡因子会发生变化，不止是被删除节点的 paren 它的平衡因子会发生变化，这个被删除节点的所有祖先节点的平衡因子都可能发生变化。

如果只观察被删除节点的 parent 的平衡因子的变化情况，有三种情况需要考虑

- parent 平衡因子从 0 变成 1 或者-1
- parent 平衡因子从-1 或 1 变成 0
- parent 平衡因子从 1 变成 2 或者从-1 变成-2

## 数据结构之----并查集

### 1.概念

并查集是一种非常简单但是非常有效的集合，它支持下面 3 种操作：

- union(root1, root2) 把集合 root2 合并入集合 root1 中，要求是 root1 和 root2 互不相交
- find(x) 搜索 x 所在的集合，返回该集合的名字
- 初始化函数， 将 s 个元素初始化为 s 个只有一个元素的子集合
  如果集合中有 n 个元素，可以用一个 0~n-1 个整数来表示这些元素，这个整数就是集合名，
  并查集的典型实现是采用数组，并用树形结构来表示元素及其所属子集的关系，回想一下堆，堆就是用数组来表达树结构，并查集是相同的道理，数组元素的索引就是这些元素的编号。

### 2.实现

#### 2.1 初始化

进行初始化的时候，数组里的每个元素都初始化为-1，这里有 3 个概念非常重要

- 每个元素都是一个单独的集合，与其他集合互不相交
- 对于刚刚初始化结束的并查集，每个元素是一个单独的集合，它的索引就是这个集合的集合名
- 每个元素的值，就是其父节点所在的索引，由于刚刚初始化，每个元素的值都是-1，-1 这个索引在数组中是不存在的，这恰好表明每个元素都没有父节点

#### 2.2 find

从 2.1 可以知道，待查找的值其实就是数组的索引，通过该索引的值就能找到它的父节点，通过父节点一层层往上查找就能找到待查找的值所在的集合。

#### 2.3 union

合并两个不相交的集合，比如 a 和 b，我们要让 a 是 b 的父节点，那么就把 b 的值设为 a 的索引。

### 3.应用（朋友圈问题）

有一个集合{0,1,2,3,4,5,6,7,8,9},共有 9 个元素，分别代表了 1 个人的编号，他们中有些人是朋友，下面的数组表达了这些人的朋友关系

```
var friends = [
    [0, 7],
    [1, 6],
    [4, 8],
    [8, 2],
    [9, 0],
    [3, 5],
    [1, 2]
];
```

## 数据结构之----散列表

散列表是表示集合，字典的另一种有效方法，它将关键码映射到某个位置上来存储元素，取值的时候，根据关键码找到对应的位置来取值。

### 1. 散列方法

散列表使用数组实现，如果关键码和索引之间有个映射关系，那么就可以通过 key 找到对应的索引，利用索引操作数组元素的时间负责度是 O(1)。
会面临两个问题：

- 数组中的索引是数字，但是关键码有可能是字符串
- 数组中的索引是连续的，关键码即使都是整数，也有可能超出索引范围

#### 1.1 hash 函数

hash，一般翻译成散列，音译是哈希，它把任意长度的输入，通过散列算法变换成固定长度的输出，这个输出结果就是散列值。
给 hash 函数一个字符串，它返回给你一个整数，这样，就解决了关键码不是整数的问题，不同的 key，可能会得到相同的 address，这种冲突的是不可避免的，好的 hash 算法，散列均匀，计算速度快。

#### 1.2 除留余数法

1.1 中解决了关键码不是整数的问题，关键码由非整数，变成了整数。但是还面临着关键码比数组索引大的问题，这时，可以使用除留余数法，假设数组大小为 m,则找一个最接近 m 或者等于 m 的质数 p 作为除数，那么求数组索引的方法便是 hash(key) = key % p
质数，能最大程度上避免冲突。

### 2.处理冲突

你给 hash 函数两个不同的字符串，它却返回了相同的结果，当然这个概率非常非常的低，真正的冲突不是 hash 函数造成的，而是除留余数法导致的。

处理冲突最有效的办法是采用开散列方法，数组中的索引只能存储一个值，如果这个值是链表，链表是可以存储多个值的。这样，就解决了冲突的问题，通过关键码找到数组索引，得到数组里存放的链表，然后通过这个链表来操作数据，需要注意的是，关键码也要做为数据存放到链表的节点上，这样才能实现查找和赋值，使用开散列发得到的链表结构。

### 3.实现

### 4.性能优化

当存储的 key 逐渐增加时，还是带来了新的问题，当每个链表储存的节点比较多时，每次查询或修改都要进行多次比较，这样，hashTable 的性能就会下降

为了解决性能问题，可以采用两种方法

- 使用搜索树
- 扩容

#### 扩容

HashTable 内部存储了存入 key 的数量，如果这个数量达到了除数的 5 倍（具体多少倍你可以自己定），那么我们就认为这个 HashTable 太拥挤了，需要扩大一下空间。用一个临时数组保存 items 的内容，然后将 items 扩大为原来的 2 倍，将临时数组里的保存的数据，重新分配到 items 中。

## 数据结构之----图

### 1. 基本概念

图：顶点集合（vertex） 和顶点间的关系（edge）组成的一种数据结构:Graph=(V, E)
有向图：顶点间的关系（edge）是有方向的，比如(0,1)和(1,0)就是两条边
无向图：边没有方向的图，(0,1)和(1,0)是一样的
完全图：可以理解为每个顶点都互相连接。
无向完全图：边和顶点的关系是 n(n-1)/2
有向完全图：边和顶点的关系是 n(n-1)
权重：边具有与之相关的数值
度：与顶点 v 关联的边数，在有向图中，以 v 为终点的有向边的数量是 v 的入度，以 v 为始点有向边的数量是出度，v 的度是入度与出度之和。
路径：从顶点 vi 出发，沿着一些边经过 vp1, vp2 ,..., vpm 到达 vj，则称（vi， vp1, vp2 ,..., vpm， vj）是从顶点 vi 到 vj 的一条路径。
路径长度：对于不带权的图，路径长度是指路径上边的条数，其实对于不带权的图，可以认为边的权值都为 1；对于带权的图，路径长度等于路径上各条边的权值之和。
连通图：任意两个顶点之间都是连通的
连通分量：非连通图的极大连通子图
生成树：一个无向连通图的生成树，是它的极小连通子图，这里的极小，是指边的数量最小

### 2.图的存储结构

#### 2.1 邻接矩阵表示

所谓邻接矩阵，就是一个二维数组，上图中的图结构可以用下面的二维数组来表示
对于 maps[i][j]:

- 如果 i==j, 则 maps[i][j]=0
- 如果 i!=j,同时(i,j)存在或者<i,j>存在，则 maps[i][j]等于 i 到 j 的权重
- 如果 i!=j，同时(i,j)不存在或者<i,j>不存在，则 maps[i][j] = max_value，这个 max_value 表示无限大，本教程用 4 个 9 表示。

#### 2.2 邻接表表示

邻接矩阵虽然可以表示图的结构，但存在缺陷，如果图中顶点的数量非常多，而边的数量非常少，那么矩阵就变的非常稀疏，存储效率就低，此时可以改为邻接表的形式来存储数据。

### 3.图的遍历

图的遍历有两种方法，一种是深度优先遍历，另一种是广度优先遍历

#### 3.1 深度优先遍历

不同于树的遍历，图中各点有可能互相连通，为了不重复遍历，必须对已经遍历过的点进行标识，示例中使用数组 visited[i]=1 标识 i 已经遍历过。
树的遍历默认从 root 根节点开始，而图不存在根节点的概念，因此在遍历时，要指定起始顶点 v，先找出 v 所能连接的所有顶点，遍历这些顶点，并对这些顶点做同 v 一样的操作。

#### 3.2 广度优先遍历

同样使用数组 visited[i]=1 标识 i 已经遍历过，和树的分层打印节点一样，需要借助队列，将顶点 v 所能连通的其他顶点放入到队列中，而后出队列，对这个刚刚对队列的顶点做和 v 相同的操作

#### 3.3 连通分量

要对所有的顶点进行检测，如果已经被访问过，那么这个点一定会落在图中已经求得的连通分量上，否则，从该顶点触发遍历图，就可以得到另一个连通分量

### 4.最小生成树

#### 4.1 Kruskal(克鲁斯卡尔) 算法

先将所有的边都存入到一个最小堆中，用权值做关键码，那么堆顶的边，一定会被至少一棵最小生成树所采用，于是将堆顶删除放入到最小生成树中，现在，堆顶是剩余的边中权值最小的，继续删除并放入到最小生成树中。

#### 4.2 prim（普里姆）算法

prim（普里姆）算法要求指定一个顶点 v，从这个顶点开始构建最小生成树。
与 kruskal 算法类似，也需要一个最小堆存储边，存储图的边
顶点 v 是第一个加入到最小生成树顶点集合中的顶点，记做 b_mst[v]=1。
每次选出一个端点在最小生成树中，另一个端点不在生成树的权值最小的边，也就是堆顶的边。将其从最小堆删除，加入到生成树中，然后将新出现的所有一个端点在生成树中，另一个端点不在生成树中的边加入到最小堆中，如此重复，直到找到 n-1 条边。

### 5. 最短路径问题

算法思想：
用 visitedArr 存储已经找到最短路径的长度，用 dis 存储顶点到各个顶点的最短路径长度，用 path 存储最短路径。
第一步：初始化 dis，设置顶点到各个顶点的最短路径长度为 INF
第二步：从顶点 v 开始，找到所能达到的顶点和路径，更新 dis,把顶点入栈。
第三步：找到距离顶点 v 最短路径的顶点 w,然后继续第二步操作

## 数据结构之---排序算法

### 1. 分而治之

分而治之，是非常重要的编程思想，它的关键之处在于不断缩小问题的规模，直到找到基线条件，而基线条件则是非常简单且易于处理的，这种思想天然的就和递归契合在一起，递归也是一个不断分解问题直到遇到最简单最易处理的情况然后加以解决的过程。

#### 1.1 归并排序
